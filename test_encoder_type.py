"""–¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ encoder_type –∏ decoder_type –≤ TRBA."""

import torch
from src.manuscript.recognizers._trba.model.model import TRBAModel

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞
num_classes = 100
hidden_size = 256
num_encoder_layers = 2
img_h = 64
img_w = 256
batch_size = 2

print("=" * 80)
print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ encoder_type –∏ decoder_type –≤ TRBA")
print("=" * 80)

# –ú–∞—Ç—Ä–∏—Ü–∞ —Ç–µ—Å—Ç–æ–≤: –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ encoder/decoder
test_configs = [
    ("LSTM", "LSTM", "Encoder: LSTM, Decoder: LSTM"),
    ("LSTM", "GRU", "Encoder: LSTM, Decoder: GRU"),
    ("GRU", "LSTM", "Encoder: GRU, Decoder: LSTM"),
    ("GRU", "GRU", "Encoder: GRU, Decoder: GRU"),
]

results = []

for encoder_type, decoder_type, desc in test_configs:
    print(f"\n{'=' * 80}")
    print(f"–¢–µ—Å—Ç: {desc}")
    print("=" * 80)

    try:
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = TRBAModel(
            num_classes=num_classes,
            hidden_size=hidden_size,
            num_encoder_layers=num_encoder_layers,
            encoder_type=encoder_type,
            decoder_type=decoder_type,
            img_h=img_h,
            img_w=img_w,
        )

        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        params = sum(p.numel() for p in model.parameters())
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {params:,}")

        # –¢–µ—Å—Ç forward pass (training)
        x = torch.randn(batch_size, 3, img_h, img_w)
        tgt = torch.randint(0, num_classes, (batch_size, 20))

        model.train()
        output_train = model(model.encode(x), text=tgt, is_train=True)
        print(f"   Training output shape: {output_train.shape}")

        # –¢–µ—Å—Ç forward pass (inference greedy)
        model.eval()
        with torch.no_grad():
            probs, preds = model(model.encode(x), is_train=False, mode="greedy")
        print(f"   Greedy inference preds shape: {preds.shape}")

        # –¢–µ—Å—Ç forward pass (inference beam)
        with torch.no_grad():
            probs, preds = model(
                model.encode(x), is_train=False, mode="beam", beam_size=3
            )
        print(f"   Beam inference preds shape: {preds.shape}")

        print(f"   ‚úì –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
        results.append((desc, params, "‚úì OK"))

    except Exception as e:
        print(f"   ‚úó –û—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
        results.append((desc, 0, f"‚úó FAILED: {str(e)[:50]}"))

# –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞
print("\n" + "=" * 80)
print("–ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
print("=" * 80)
print(f"{'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è':<40} {'–ü–∞—Ä–∞–º–µ—Ç—Ä—ã':>15} {'–°—Ç–∞—Ç—É—Å':<20}")
print("-" * 80)

for desc, params, status in results:
    params_str = f"{params:,}" if params > 0 else "N/A"
    print(f"{desc:<40} {params_str:>15} {status:<20}")

print("=" * 80)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π
if len(results) == 4:
    lstm_lstm = results[0][1]
    gru_gru = results[3][1]

    if lstm_lstm > 0 and gru_gru > 0:
        diff = lstm_lstm - gru_gru
        diff_pct = (diff / lstm_lstm) * 100

        print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ LSTM+LSTM vs GRU+GRU:")
        print(f"   LSTM+LSTM: {lstm_lstm:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        print(f"   GRU+GRU:   {gru_gru:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        print(f"   –≠–∫–æ–Ω–æ–º–∏—è:  {diff:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ({diff_pct:.1f}%)")
        print(f"   GRU+GRU —ç–∫–æ–Ω–æ–º–∏—Ç ~{diff_pct:.0f}% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤!")

print("\n" + "=" * 80)
print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
print("=" * 80)
