"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä TRBA –Ω–∞ CPU.

–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º:
1. –†–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ encoder layers (1, 2, 3, 4)
2. –†–∞–∑–Ω—ã–π hidden_size (128, 256, 512)
3. –†–µ–∂–∏–º—ã –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è (greedy vs beam)

–¶–µ–ª—å: –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ capacity –¥–ª—è CPU.
"""

import time
import json
import torch
import cv2

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞–ø—Ä—è–º—É—é
from manuscript.recognizers._trba.model.model import TRBAModel
from manuscript.recognizers._trba.data.transforms import load_charset, get_val_transform

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
TEST_IMAGE = r"C:\Users\USER\Desktop\t2.png"
NUM_IMAGES = 25  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ø–∏–π –¥–ª—è —Ç–µ—Å—Ç–∞
CHARSET_PATH = r"C:\Users\USER\manuscript-ocr\src\manuscript\recognizers\_trba\configs\charset.txt"

# –ó–∞–≥—Ä—É–∑–∫–∞ charset
itos, stoi = load_charset(CHARSET_PATH)
num_classes_full = len(itos)

print("=" * 80)
print("üî¨ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–ó–ù–´–• –ê–†–•–ò–¢–ï–ö–¢–£–† TRBA –ù–ê CPU")
print("=" * 80)
print(f"–¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {TEST_IMAGE}")
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤: {NUM_IMAGES} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
print(f"–ü–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å: {num_classes_full} —Å–∏–º–≤–æ–ª–æ–≤")
print()

# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
transform = get_val_transform(img_h=64, img_w=256)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
img = cv2.imread(TEST_IMAGE)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
transformed = transform(image=img)
image_tensor = transformed["image"].unsqueeze(0)  # [1, 3, 64, 256]

# –°–æ–∑–¥–∞—ë–º –±–∞—Ç—á
batch_tensor = image_tensor.repeat(NUM_IMAGES, 1, 1, 1)  # [N, 3, 64, 256]
print(f"‚úÖ –ë–∞—Ç—á –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω: {batch_tensor.shape}")
print()

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
configs = [
    # –ù–∞–∑–≤–∞–Ω–∏–µ, num_encoder_layers, hidden_size, img_h, img_w, cnn_in_channels, cnn_out_channels, –æ–ø–∏—Å–∞–Ω–∏–µ
    ("–ú–∏–∫—Ä–æ (1√ó128, 32√ó128, CNN256)", 1, 128, 32, 128, 3, 256, "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: –º–∞–ª–µ–Ω—å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + –ª–µ–≥–∫–∏–π CNN"),
    ("–õ–µ–≥–∫–∞—è CNN (2√ó256, CNN256)", 2, 256, 64, 256, 3, 256, "–õ–µ–≥–∫–∏–π CNN backbone"),
    ("–°—Ä–µ–¥–Ω—è—è CNN (2√ó256, CNN384)", 2, 256, 64, 256, 3, 384, "–°—Ä–µ–¥–Ω–∏–π CNN backbone"),
    ("–°—Ç–∞–Ω–¥–∞—Ä—Ç (2√ó256, CNN512)", 2, 256, 64, 256, 3, 512, "Default –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"),
    ("–¢—è–∂–µ–ª–∞—è CNN (2√ó256, CNN768)", 2, 256, 64, 256, 3, 768, "–¢—è–∂–µ–ª—ã–π CNN backbone"),
    ("–õ–µ–≥–∫–∞—è + 1 encoder (1√ó256, CNN384)", 1, 256, 64, 256, 3, 384, "1 encoder + —Å—Ä–µ–¥–Ω–∏–π CNN"),
    ("–ì–ª—É–±–æ–∫–∞—è + –ª–µ–≥–∫–∞—è CNN (3√ó256, CNN384)", 3, 256, 64, 256, 3, 384, "3 encoder + —Å—Ä–µ–¥–Ω–∏–π CNN"),
    ("–¢—è–∂–µ–ª–∞—è (2√ó512, CNN512)", 2, 512, 64, 256, 3, 512, "–ë–æ–ª—å—à–æ–π hidden_size"),
]

results = []

# === –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
for config_name, num_enc_layers, hidden_size, img_h, img_w, cnn_in, cnn_out, description in configs:
    print("=" * 80)
    print(f"üìä –¢–µ—Å—Ç: {config_name}")
    print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {description}")
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: enc_layers={num_enc_layers}, hidden={hidden_size}, "
          f"img={img_h}√ó{img_w}, CNN_in={cnn_in}, CNN_out={cnn_out}")
    print("-" * 80)
    
    # –†–µ—Å–∞–π–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–¥ –Ω—É–∂–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    resized_img = cv2.resize(img, (img_w, img_h))
    transform_temp = get_val_transform(img_h=img_h, img_w=img_w)
    transformed_temp = transform_temp(image=resized_img)
    image_tensor_temp = transformed_temp["image"].unsqueeze(0)
    batch_tensor_temp = image_tensor_temp.repeat(NUM_IMAGES, 1, 1, 1)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = TRBAModel(
        num_classes=num_classes_full,
        hidden_size=hidden_size,
        num_encoder_layers=num_enc_layers,
        img_h=img_h,
        img_w=img_w,
        cnn_in_channels=cnn_in,
        cnn_out_channels=cnn_out,
        sos_id=stoi["<SOS>"],
        eos_id=stoi["<EOS>"],
        pad_id=stoi["<PAD>"],
        blank_id=stoi.get("<BLANK>", None),
    )
    model.eval()
    
    # –ü–æ–¥—Å—á—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    total_params = sum(p.numel() for p in model.parameters())
    encoder_params = sum(p.numel() for p in model.enc_rnn.parameters())
    cnn_params = sum(p.numel() for p in model.cnn.parameters())
    attn_params = sum(p.numel() for p in model.attn.parameters())
    
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"      Total:    {total_params:>10,} ({total_params*4/(1024*1024):>6.2f} MB)")
    print(f"      CNN:      {cnn_params:>10,} ({cnn_params/total_params*100:>5.1f}%)")
    print(f"      Encoder:  {encoder_params:>10,} ({encoder_params/total_params*100:>5.1f}%)")
    print(f"      Attention: {attn_params:>10,} ({attn_params/total_params*100:>5.1f}%)")
    
    # === –¢–µ—Å—Ç 1: Greedy mode ===
    print("\n   üèÉ Greedy mode:")
    
    # –ü—Ä–æ–≥—Ä–µ–≤
    with torch.no_grad():
        _ = model(batch_tensor_temp[:2], is_train=False, mode="greedy", batch_max_length=25)
    
    # –ó–∞–º–µ—Ä
    start = time.perf_counter()
    with torch.no_grad():
        probs_greedy, preds_greedy = model(
            batch_tensor_temp,
            is_train=False,
            mode="greedy",
            batch_max_length=25
        )
    greedy_time = time.perf_counter() - start
    greedy_fps = NUM_IMAGES / greedy_time
    
    print(f"      –í—Ä–µ–º—è: {greedy_time:.3f}s ({greedy_fps:.1f} img/s)")
    print(f"      –ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {greedy_time/NUM_IMAGES*1000:.1f}ms")
    
    # === –¢–µ—Å—Ç 2: Beam search mode ===
    print("\n   üîç Beam search mode (beam_size=8):")
    
    # –ü—Ä–æ–≥—Ä–µ–≤
    with torch.no_grad():
        _ = model(batch_tensor_temp[:2], is_train=False, mode="beam", 
                 beam_size=8, batch_max_length=25)
    
    # –ó–∞–º–µ—Ä
    start = time.perf_counter()
    with torch.no_grad():
        probs_beam, preds_beam = model(
            batch_tensor_temp,
            is_train=False,
            mode="beam",
            beam_size=8,
            batch_max_length=25
        )
    beam_time = time.perf_counter() - start
    beam_fps = NUM_IMAGES / beam_time
    
    print(f"      –í—Ä–µ–º—è: {beam_time:.3f}s ({beam_fps:.1f} img/s)")
    print(f"      –ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {beam_time/NUM_IMAGES*1000:.1f}ms")
    print(f"      –ú–µ–¥–ª–µ–Ω–Ω–µ–µ greedy –≤: {beam_time/greedy_time:.1f}√ó")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results.append({
        "name": config_name,
        "description": description,
        "num_encoder_layers": num_enc_layers,
        "hidden_size": hidden_size,
        "img_h": img_h,
        "img_w": img_w,
        "cnn_in_channels": cnn_in,
        "cnn_out_channels": cnn_out,
        "total_params": total_params,
        "encoder_params": encoder_params,
        "cnn_params": cnn_params,
        "attn_params": attn_params,
        "greedy_time": greedy_time,
        "greedy_fps": greedy_fps,
        "greedy_ms_per_img": greedy_time / NUM_IMAGES * 1000,
        "beam_time": beam_time,
        "beam_fps": beam_fps,
        "beam_ms_per_img": beam_time / NUM_IMAGES * 1000,
        "beam_slowdown": beam_time / greedy_time,
    })
    
    print()

# === –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ===
print("=" * 80)
print("üìà –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï")
print("=" * 80)
print()

# –¢–∞–±–ª–∏—Ü–∞ greedy mode
print("üèÉ GREEDY MODE:")
print("-" * 80)
print(f"{'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è':<35} {'Params':>10} {'CNN%':>6} {'Time':>8} {'FPS':>8} {'ms/img':>8}")
print("-" * 80)

baseline_greedy = results[0]["greedy_time"]
for r in results:
    speedup = baseline_greedy / r["greedy_time"]
    marker = "‚≠ê" if speedup > 1.2 else "  "
    cnn_pct = r["cnn_params"] / r["total_params"] * 100
    print(f"{marker}{r['name']:<33} {r['total_params']:>10,} {cnn_pct:>5.1f}% "
          f"{r['greedy_time']:>7.2f}s {r['greedy_fps']:>7.1f} {r['greedy_ms_per_img']:>7.1f}")

print()

# –¢–∞–±–ª–∏—Ü–∞ beam mode
print("üîç BEAM SEARCH MODE (beam_size=8):")
print("-" * 80)
print(f"{'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è':<35} {'Params':>10} {'CNN%':>6} {'Time':>8} {'FPS':>8} {'ms/img':>8}")
print("-" * 80)

baseline_beam = results[0]["beam_time"]
for r in results:
    speedup = baseline_beam / r["beam_time"]
    marker = "‚≠ê" if speedup > 1.2 else "  "
    cnn_pct = r["cnn_params"] / r["total_params"] * 100
    print(f"{marker}{r['name']:<33} {r['total_params']:>10,} {cnn_pct:>5.1f}% "
          f"{r['beam_time']:>7.2f}s {r['beam_fps']:>7.1f} {r['beam_ms_per_img']:>7.1f}")

print()

# –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
print("üì¶ –î–ï–¢–ê–õ–¨–ù–ê–Ø –†–ê–ó–ë–ò–í–ö–ê –ü–û –ö–û–ú–ü–û–ù–ï–ù–¢–ê–ú:")
print("-" * 100)
print(f"{'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è':<35} {'Total MB':>9} {'CNN MB':>9} {'Enc MB':>9} {'Attn MB':>9}")
print("-" * 100)

for r in results:
    total_mb = r['total_params'] * 4 / (1024 * 1024)
    cnn_mb = r['cnn_params'] * 4 / (1024 * 1024)
    enc_mb = r['encoder_params'] * 4 / (1024 * 1024)
    attn_mb = r['attn_params'] * 4 / (1024 * 1024)
    
    print(f"{r['name']:<35} {total_mb:>8.1f}  {cnn_mb:>8.1f}  {enc_mb:>8.1f}  {attn_mb:>8.1f}")

print()

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline
print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –° BASELINE (–ú–∏–∫—Ä–æ):")
print("-" * 80)
print(f"{'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è':<35} {'Greedy':>12} {'Beam':>12} {'Params':>12}")
print("-" * 80)

for r in results:
    greedy_ratio = r["greedy_time"] / baseline_greedy
    beam_ratio = r["beam_time"] / baseline_beam
    params_ratio = r["total_params"] / results[0]["total_params"]
    
    print(f"{r['name']:<35} "
          f"{greedy_ratio:>11.2f}√ó {beam_ratio:>11.2f}√ó {params_ratio:>11.2f}√ó")

print()

# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
print("=" * 80)
print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
print("=" * 80)

# –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—É—é –±—ã—Å—Ç—Ä—É—é –¥–ª—è greedy
fastest_greedy = min(results, key=lambda x: x["greedy_time"])
print(f"\nüèÜ –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è (greedy): {fastest_greedy['name']}")
print(f"   {fastest_greedy['greedy_fps']:.1f} img/s ({fastest_greedy['greedy_ms_per_img']:.1f}ms/img)")
print(f"   –†–∞–∑–º–µ—Ä: {fastest_greedy['total_params']*4/(1024*1024):.1f} MB")

# –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å (—Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ)
# –ò—â–µ–º –º–æ–¥–µ–ª—å ~20-30 MB, —Å —Ö–æ—Ä–æ—à–µ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é
best_balance = None
for r in results:
    mb = r['total_params'] * 4 / (1024 * 1024)
    if 15 < mb < 35 and r['greedy_fps'] > fastest_greedy['greedy_fps'] * 0.7:
        if best_balance is None or r['greedy_fps'] > best_balance['greedy_fps']:
            best_balance = r

if best_balance:
    print(f"\n‚öñÔ∏è  –õ—É—á—à–∏–π –±–∞–ª–∞–Ω—Å: {best_balance['name']}")
    print(f"   {best_balance['greedy_fps']:.1f} img/s (greedy), {best_balance['beam_fps']:.1f} img/s (beam)")
    print(f"   –†–∞–∑–º–µ—Ä: {best_balance['total_params']*4/(1024*1024):.1f} MB")

# –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—É—é –∫–æ–º–ø–∞–∫—Ç–Ω—É—é
smallest = min(results, key=lambda x: x["total_params"])
print(f"\nüì¶ –°–∞–º–∞—è –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è: {smallest['name']}")
print(f"   {smallest['total_params']:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ({smallest['total_params']*4/(1024*1024):.1f} MB)")
print(f"   {smallest['greedy_fps']:.1f} img/s (greedy)")

# –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è CNN
print(f"\nüî¨ –í–õ–ò–Ø–ù–ò–ï CNN OUT_CHANNELS –ù–ê –†–ê–ó–ú–ï–†:")
cnn_configs = [r for r in results if r['num_encoder_layers'] == 2 and r['hidden_size'] == 256]
if len(cnn_configs) > 1:
    for r in cnn_configs:
        cnn_mb = r['cnn_params'] * 4 / (1024 * 1024)
        total_mb = r['total_params'] * 4 / (1024 * 1024)
        print(f"   CNN={r['cnn_out_channels']}: {cnn_mb:.1f} MB ({r['cnn_params']/r['total_params']*100:.1f}% –æ—Ç {total_mb:.1f} MB)")

print()
print("=" * 80)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
output_file = "architecture_benchmark_results.json"
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
print("=" * 80)
