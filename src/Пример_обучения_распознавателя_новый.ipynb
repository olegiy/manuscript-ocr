{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pasha\\manuscript-ocr\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\pasha\\manuscript-ocr\\env\\Lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "[2025-11-04 18:44:55] Start training\n",
            "[2025-11-04 18:44:55] Experiment dir: experiments/trba_exp4\n",
            "[2025-11-04 18:44:55] Seed: 42\n",
            "[2025-11-04 18:44:55] Saved config to exp_dir/config.json\n",
            "c:\\Users\\pasha\\manuscript-ocr\\env\\Lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "[2025-11-04 18:44:55] Start training\n",
            "[2025-11-04 18:44:55] Experiment dir: experiments/trba_exp4\n",
            "[2025-11-04 18:44:55] Seed: 42\n",
            "[2025-11-04 18:44:55] Saved config to exp_dir/config.json\n",
            "[2025-11-04 18:44:55] Device: cuda\n",
            "[2025-11-04 18:44:55] Charset loaded: 194 tokens\n",
            "[2025-11-04 18:44:55] Device: cuda\n",
            "[2025-11-04 18:44:55] Charset loaded: 194 tokens\n",
            "[2025-11-04 18:44:55] Using default pretrained weights: trba_exp_1_64.pth (GitHub release)\n",
            "[2025-11-04 18:44:55] Default pretrain config: https://github.com/konstantinkozhin/manuscript-ocr/releases/download/v0.1.0/trba_exp_1_64.json\n",
            "[2025-11-04 18:44:55] Failed to load pretrained from https://github.com/konstantinkozhin/manuscript-ocr/releases/download/v0.1.0/trba_exp_1_64.pth: PytorchStreamReader failed reading zip archive: failed finding central directory\n",
            "[2025-11-04 18:44:55] Pretrained load failed from https://github.com/konstantinkozhin/manuscript-ocr/releases/download/v0.1.0/trba_exp_1_64.pth. Proceeding with random init.\n",
            "[2025-11-04 18:44:55] Using default pretrained weights: trba_exp_1_64.pth (GitHub release)\n",
            "[2025-11-04 18:44:55] Default pretrain config: https://github.com/konstantinkozhin/manuscript-ocr/releases/download/v0.1.0/trba_exp_1_64.json\n",
            "[2025-11-04 18:44:55] Failed to load pretrained from https://github.com/konstantinkozhin/manuscript-ocr/releases/download/v0.1.0/trba_exp_1_64.pth: PytorchStreamReader failed reading zip archive: failed finding central directory\n",
            "[2025-11-04 18:44:55] Pretrained load failed from https://github.com/konstantinkozhin/manuscript-ocr/releases/download/v0.1.0/trba_exp_1_64.pth. Proceeding with random init.\n",
            "[2025-11-04 18:44:55] Freeze policy applied: cnn: NONE (no freezing)\n",
            "[2025-11-04 18:44:55] Freeze policy applied: enc_rnn: NONE (no freezing)\n",
            "[2025-11-04 18:44:55] Freeze policy applied: attention: NONE (no freezing)\n",
            "[2025-11-04 18:44:55] Parameters: trainable=45,162,931 | frozen=0 | total=45,162,931\n",
            "[2025-11-04 18:44:55] Using U-Net attention mask (trained end-to-end via recognition loss)\n",
            "[2025-11-04 18:44:55] Freeze policy applied: cnn: NONE (no freezing)\n",
            "[2025-11-04 18:44:55] Freeze policy applied: enc_rnn: NONE (no freezing)\n",
            "[2025-11-04 18:44:55] Freeze policy applied: attention: NONE (no freezing)\n",
            "[2025-11-04 18:44:55] Parameters: trainable=45,162,931 | frozen=0 | total=45,162,931\n",
            "[2025-11-04 18:44:55] Using U-Net attention mask (trained end-to-end via recognition loss)\n",
            "c:\\Users\\pasha\\manuscript-ocr\\src\\manuscript\\recognizers\\_trba\\training\\train.py:771: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler()\n",
            "c:\\Users\\pasha\\manuscript-ocr\\src\\manuscript\\recognizers\\_trba\\training\\train.py:771: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler()\n",
            "                                                                            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OCRDatasetAttn] C:\\shared\\orig_cyrillic\\train.tsv: пропущено 18 записей.\n",
            "  - empty_label: 2\n",
            "    примеры: ['yob3873.png', 'yob4721.png']\n",
            "  - too_long: 16\n",
            "    примеры: [('dem28690.png', 38, 'eff>30'), ('dem28865.png', 36, 'eff>30'), ('dem30412.png', 31, 'eff>30'), ('dem30417.png', 40, 'eff>30'), ('dem34128.png', 31, 'eff>30'), ('dem34427.png', 31, 'eff>30'), ('pe6839.png', 31, 'eff>30'), ('www11236.png', 32, 'eff>30')]\n",
            "[OCRDatasetAttn] Lazy image validation is enabled; unreadable images will be skipped during the first access.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 18:45:02] Validation strategy:                 \n",
            "[2025-11-04 18:45:02]   Dataset 0: using separate validation set from C:\\shared\\orig_cyrillic\\test\n",
            "[2025-11-04 18:45:02] Datasets: train=72268 samples across 1 set(s); val=1544 samples across 1 set(s)\n",
            "[2025-11-04 18:45:02] Loaders: train_batches/epoch=1130; val_batches=25; batch_size=64\n",
            "[2025-11-04 18:45:02] Validation strategy:                 \n",
            "[2025-11-04 18:45:02]   Dataset 0: using separate validation set from C:\\shared\\orig_cyrillic\\test\n",
            "[2025-11-04 18:45:02] Datasets: train=72268 samples across 1 set(s); val=1544 samples across 1 set(s)\n",
            "[2025-11-04 18:45:02] Loaders: train_batches/epoch=1130; val_batches=25; batch_size=64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OCRDatasetAttn] Lazy image validation is enabled; unreadable images will be skipped during the first access.\n",
            "Datasets: train=72268 samples across 1 set(s); val=1544 samples across 1 set(s)\n",
            "Loaders: train_batches/epoch=1130; val_batches=25; batch_size=64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train 1/100:   0%|          | 0/1130 [00:00<?, ?it/s]c:\\Users\\pasha\\manuscript-ocr\\src\\manuscript\\recognizers\\_trba\\training\\train.py:987: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "c:\\Users\\pasha\\manuscript-ocr\\src\\manuscript\\recognizers\\_trba\\training\\train.py:987: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "[2025-11-04 18:49:09] Epoch 1/100: train_loss=2.7886                                      \n",
            "[2025-11-04 18:49:09] Epoch 1/100: train_loss=2.7886                                      \n",
            "Valid Set 0 1/100:   0%|          | 0/25 [00:00<?, ?it/s]c:\\Users\\pasha\\manuscript-ocr\\src\\manuscript\\recognizers\\_trba\\training\\train.py:1076: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "c:\\Users\\pasha\\manuscript-ocr\\src\\manuscript\\recognizers\\_trba\\training\\train.py:1076: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "                                                                                   [2025-11-04 18:49:19] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 18:49:19] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 18:49:20] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 18:49:20] Epoch 001/100 | train_loss=2.7886 | val_loss=2.5497 | acc=0.0006 | CER=0.8474 | WER=1.0356 | acc_beam=0.0019 | CER_beam=0.8277 | WER_beam=1.0022 | lr=1.00e-03\n",
            "[2025-11-04 18:49:20] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 18:49:20] Epoch 001/100 | train_loss=2.7886 | val_loss=2.5497 | acc=0.0006 | CER=0.8474 | WER=1.0356 | acc_beam=0.0019 | CER_beam=0.8277 | WER_beam=1.0022 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001/100 | train_loss=2.7886 | val_loss=2.5497 | acc=0.0006 | CER=0.8474 | WER=1.0356 | acc_beam=0.0019 | CER_beam=0.8277 | WER_beam=1.0022 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 18:49:24] New best val_loss: 2.5497 (epoch 1)\n",
            "[2025-11-04 18:49:26] New best acc: 0.0006 (epoch 1)\n",
            "Train 2/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 18:49:26] New best acc: 0.0006 (epoch 1)\n",
            "[2025-11-04 18:53:39] Epoch 2/100: train_loss=1.8653                                      \n",
            "[2025-11-04 18:53:39] Epoch 2/100: train_loss=1.8653                                      \n",
            "                                                                                   [2025-11-04 18:53:46] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 18:53:46] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 18:53:48] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 18:53:48] Epoch 002/100 | train_loss=1.8653 | val_loss=1.9623 | acc=0.0130 | CER=0.6201 | WER=0.9837 | acc_beam=0.0175 | CER_beam=0.6238 | WER_beam=0.9736 | lr=1.00e-03\n",
            "[2025-11-04 18:53:48] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 18:53:48] Epoch 002/100 | train_loss=1.8653 | val_loss=1.9623 | acc=0.0130 | CER=0.6201 | WER=0.9837 | acc_beam=0.0175 | CER_beam=0.6238 | WER_beam=0.9736 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002/100 | train_loss=1.8653 | val_loss=1.9623 | acc=0.0130 | CER=0.6201 | WER=0.9837 | acc_beam=0.0175 | CER_beam=0.6238 | WER_beam=0.9736 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 18:53:51] New best val_loss: 1.9623 (epoch 2)\n",
            "[2025-11-04 18:53:54] New best acc: 0.0130 (epoch 2)\n",
            "Train 3/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 18:53:54] New best acc: 0.0130 (epoch 2)\n",
            "[2025-11-04 18:57:59] Epoch 3/100: train_loss=1.0233                                      \n",
            "[2025-11-04 18:57:59] Epoch 3/100: train_loss=1.0233                                      \n",
            "                                                                                   [2025-11-04 18:58:07] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 18:58:07] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 18:58:09] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 18:58:09] Epoch 003/100 | train_loss=1.0233 | val_loss=1.1650 | acc=0.1205 | CER=0.3755 | WER=0.8594 | acc_beam=0.1354 | CER_beam=0.3583 | WER_beam=0.8403 | lr=1.00e-03\n",
            "[2025-11-04 18:58:09] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 18:58:09] Epoch 003/100 | train_loss=1.0233 | val_loss=1.1650 | acc=0.1205 | CER=0.3755 | WER=0.8594 | acc_beam=0.1354 | CER_beam=0.3583 | WER_beam=0.8403 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003/100 | train_loss=1.0233 | val_loss=1.1650 | acc=0.1205 | CER=0.3755 | WER=0.8594 | acc_beam=0.1354 | CER_beam=0.3583 | WER_beam=0.8403 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 18:58:12] New best val_loss: 1.1650 (epoch 3)\n",
            "[2025-11-04 18:58:15] New best acc: 0.1205 (epoch 3)\n",
            "Train 4/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 18:58:15] New best acc: 0.1205 (epoch 3)\n",
            "[2025-11-04 19:02:18] Epoch 4/100: train_loss=0.6242                                      \n",
            "[2025-11-04 19:02:18] Epoch 4/100: train_loss=0.6242                                      \n",
            "                                                                                   [2025-11-04 19:02:26] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:02:26] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:02:28] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:02:28] Epoch 004/100 | train_loss=0.6242 | val_loss=0.9425 | acc=0.1891 | CER=0.2984 | WER=0.7843 | acc_beam=0.2001 | CER_beam=0.2964 | WER_beam=0.7678 | lr=1.00e-03\n",
            "[2025-11-04 19:02:28] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:02:28] Epoch 004/100 | train_loss=0.6242 | val_loss=0.9425 | acc=0.1891 | CER=0.2984 | WER=0.7843 | acc_beam=0.2001 | CER_beam=0.2964 | WER_beam=0.7678 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004/100 | train_loss=0.6242 | val_loss=0.9425 | acc=0.1891 | CER=0.2984 | WER=0.7843 | acc_beam=0.2001 | CER_beam=0.2964 | WER_beam=0.7678 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:02:31] New best val_loss: 0.9425 (epoch 4)\n",
            "[2025-11-04 19:02:33] New best acc: 0.1891 (epoch 4)\n",
            "Train 5/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:02:33] New best acc: 0.1891 (epoch 4)\n",
            "[2025-11-04 19:06:35] Epoch 5/100: train_loss=0.4650                                      \n",
            "[2025-11-04 19:06:35] Epoch 5/100: train_loss=0.4650                                      \n",
            "                                                                                   [2025-11-04 19:06:44] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:06:44] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:06:45] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:06:45] Epoch 005/100 | train_loss=0.4650 | val_loss=0.8182 | acc=0.2494 | CER=0.2525 | WER=0.7172 | acc_beam=0.2694 | CER_beam=0.2392 | WER_beam=0.6891 | lr=1.00e-03\n",
            "[2025-11-04 19:06:45] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:06:45] Epoch 005/100 | train_loss=0.4650 | val_loss=0.8182 | acc=0.2494 | CER=0.2525 | WER=0.7172 | acc_beam=0.2694 | CER_beam=0.2392 | WER_beam=0.6891 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005/100 | train_loss=0.4650 | val_loss=0.8182 | acc=0.2494 | CER=0.2525 | WER=0.7172 | acc_beam=0.2694 | CER_beam=0.2392 | WER_beam=0.6891 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:06:48] New best val_loss: 0.8182 (epoch 5)\n",
            "[2025-11-04 19:06:50] New best acc: 0.2494 (epoch 5)\n",
            "Train 6/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:06:50] New best acc: 0.2494 (epoch 5)\n",
            "[2025-11-04 19:10:54] Epoch 6/100: train_loss=0.3796                                      \n",
            "[2025-11-04 19:10:54] Epoch 6/100: train_loss=0.3796                                      \n",
            "                                                                                   [2025-11-04 19:11:01] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:11:01] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:11:03] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:11:03] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:11:03] Epoch 006/100 | train_loss=0.3796 | val_loss=0.7291 | acc=0.2811 | CER=0.2314 | WER=0.6934 | acc_beam=0.3031 | CER_beam=0.2138 | WER_beam=0.6535 | lr=1.00e-03\n",
            "[2025-11-04 19:11:03] Epoch 006/100 | train_loss=0.3796 | val_loss=0.7291 | acc=0.2811 | CER=0.2314 | WER=0.6934 | acc_beam=0.3031 | CER_beam=0.2138 | WER_beam=0.6535 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006/100 | train_loss=0.3796 | val_loss=0.7291 | acc=0.2811 | CER=0.2314 | WER=0.6934 | acc_beam=0.3031 | CER_beam=0.2138 | WER_beam=0.6535 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:11:06] New best val_loss: 0.7291 (epoch 6)\n",
            "[2025-11-04 19:11:08] New best acc: 0.2811 (epoch 6)\n",
            "Train 7/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:11:08] New best acc: 0.2811 (epoch 6)\n",
            "[2025-11-04 19:15:13] Epoch 7/100: train_loss=0.3208                                      \n",
            "[2025-11-04 19:15:13] Epoch 7/100: train_loss=0.3208                                      \n",
            "                                                                                   [2025-11-04 19:15:21] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:15:21] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:15:23] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:15:23] Epoch 007/100 | train_loss=0.3208 | val_loss=0.7382 | acc=0.3057 | CER=0.2134 | WER=0.6677 | acc_beam=0.3193 | CER_beam=0.2073 | WER_beam=0.6429 | lr=1.00e-03\n",
            "[2025-11-04 19:15:23] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:15:23] Epoch 007/100 | train_loss=0.3208 | val_loss=0.7382 | acc=0.3057 | CER=0.2134 | WER=0.6677 | acc_beam=0.3193 | CER_beam=0.2073 | WER_beam=0.6429 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007/100 | train_loss=0.3208 | val_loss=0.7382 | acc=0.3057 | CER=0.2134 | WER=0.6677 | acc_beam=0.3193 | CER_beam=0.2073 | WER_beam=0.6429 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:15:25] New best acc: 0.3057 (epoch 7)\n",
            "[2025-11-04 19:19:29] Epoch 8/100: train_loss=0.2847                                      \n",
            "[2025-11-04 19:19:29] Epoch 8/100: train_loss=0.2847                                      \n",
            "                                                                                   [2025-11-04 19:19:37] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:19:37] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:19:39] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:19:39] Epoch 008/100 | train_loss=0.2847 | val_loss=0.6717 | acc=0.3258 | CER=0.2046 | WER=0.6346 | acc_beam=0.3459 | CER_beam=0.1939 | WER_beam=0.6090 | lr=1.00e-03\n",
            "[2025-11-04 19:19:39] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:19:39] Epoch 008/100 | train_loss=0.2847 | val_loss=0.6717 | acc=0.3258 | CER=0.2046 | WER=0.6346 | acc_beam=0.3459 | CER_beam=0.1939 | WER_beam=0.6090 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008/100 | train_loss=0.2847 | val_loss=0.6717 | acc=0.3258 | CER=0.2046 | WER=0.6346 | acc_beam=0.3459 | CER_beam=0.1939 | WER_beam=0.6090 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:19:42] New best val_loss: 0.6717 (epoch 8)\n",
            "[2025-11-04 19:19:45] New best acc: 0.3258 (epoch 8)\n",
            "Train 9/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:19:45] New best acc: 0.3258 (epoch 8)\n",
            "[2025-11-04 19:23:49] Epoch 9/100: train_loss=0.2438                                      \n",
            "[2025-11-04 19:23:49] Epoch 9/100: train_loss=0.2438                                      \n",
            "                                                                                   [2025-11-04 19:23:57] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:23:57] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:23:59] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:23:59] Epoch 009/100 | train_loss=0.2438 | val_loss=0.6685 | acc=0.3329 | CER=0.2004 | WER=0.6318 | acc_beam=0.3510 | CER_beam=0.1879 | WER_beam=0.6078 | lr=1.00e-03\n",
            "[2025-11-04 19:23:59] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:23:59] Epoch 009/100 | train_loss=0.2438 | val_loss=0.6685 | acc=0.3329 | CER=0.2004 | WER=0.6318 | acc_beam=0.3510 | CER_beam=0.1879 | WER_beam=0.6078 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009/100 | train_loss=0.2438 | val_loss=0.6685 | acc=0.3329 | CER=0.2004 | WER=0.6318 | acc_beam=0.3510 | CER_beam=0.1879 | WER_beam=0.6078 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:24:02] New best val_loss: 0.6685 (epoch 9)\n",
            "[2025-11-04 19:24:05] New best acc: 0.3329 (epoch 9)\n",
            "Train 10/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:24:05] New best acc: 0.3329 (epoch 9)\n",
            "[2025-11-04 19:28:09] Epoch 10/100: train_loss=0.2264                                      \n",
            "[2025-11-04 19:28:09] Epoch 10/100: train_loss=0.2264                                      \n",
            "                                                                                    [2025-11-04 19:28:17] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:28:17] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:28:19] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:28:19] Epoch 010/100 | train_loss=0.2264 | val_loss=0.7880 | acc=0.3355 | CER=0.2241 | WER=0.6645 | acc_beam=0.3517 | CER_beam=0.2060 | WER_beam=0.6185 | lr=1.00e-03\n",
            "[2025-11-04 19:28:19] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:28:19] Epoch 010/100 | train_loss=0.2264 | val_loss=0.7880 | acc=0.3355 | CER=0.2241 | WER=0.6645 | acc_beam=0.3517 | CER_beam=0.2060 | WER_beam=0.6185 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010/100 | train_loss=0.2264 | val_loss=0.7880 | acc=0.3355 | CER=0.2241 | WER=0.6645 | acc_beam=0.3517 | CER_beam=0.2060 | WER_beam=0.6185 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:28:22] New best acc: 0.3355 (epoch 10)\n",
            "[2025-11-04 19:32:26] Epoch 11/100: train_loss=0.2063                                      \n",
            "[2025-11-04 19:32:26] Epoch 11/100: train_loss=0.2063                                      \n",
            "                                                                                    [2025-11-04 19:32:34] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:32:34] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:32:36] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:32:36] Epoch 011/100 | train_loss=0.2063 | val_loss=0.6474 | acc=0.3614 | CER=0.1844 | WER=0.6022 | acc_beam=0.3834 | CER_beam=0.1771 | WER_beam=0.5711 | lr=1.00e-03\n",
            "[2025-11-04 19:32:36] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:32:36] Epoch 011/100 | train_loss=0.2063 | val_loss=0.6474 | acc=0.3614 | CER=0.1844 | WER=0.6022 | acc_beam=0.3834 | CER_beam=0.1771 | WER_beam=0.5711 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011/100 | train_loss=0.2063 | val_loss=0.6474 | acc=0.3614 | CER=0.1844 | WER=0.6022 | acc_beam=0.3834 | CER_beam=0.1771 | WER_beam=0.5711 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:32:39] New best val_loss: 0.6474 (epoch 11)\n",
            "[2025-11-04 19:32:41] New best acc: 0.3614 (epoch 11)\n",
            "Train 12/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:32:41] New best acc: 0.3614 (epoch 11)\n",
            "[2025-11-04 19:36:43] Epoch 12/100: train_loss=0.1827                                      \n",
            "[2025-11-04 19:36:43] Epoch 12/100: train_loss=0.1827                                      \n",
            "                                                                                    [2025-11-04 19:36:51] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:36:51] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:36:53] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:36:53] Epoch 012/100 | train_loss=0.1827 | val_loss=0.6103 | acc=0.3789 | CER=0.1775 | WER=0.5860 | acc_beam=0.3899 | CER_beam=0.1699 | WER_beam=0.5636 | lr=1.00e-03\n",
            "[2025-11-04 19:36:53] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:36:53] Epoch 012/100 | train_loss=0.1827 | val_loss=0.6103 | acc=0.3789 | CER=0.1775 | WER=0.5860 | acc_beam=0.3899 | CER_beam=0.1699 | WER_beam=0.5636 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012/100 | train_loss=0.1827 | val_loss=0.6103 | acc=0.3789 | CER=0.1775 | WER=0.5860 | acc_beam=0.3899 | CER_beam=0.1699 | WER_beam=0.5636 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:36:56] New best val_loss: 0.6103 (epoch 12)\n",
            "[2025-11-04 19:36:59] New best acc: 0.3789 (epoch 12)\n",
            "Train 13/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:36:59] New best acc: 0.3789 (epoch 12)\n",
            "[2025-11-04 19:41:05] Epoch 13/100: train_loss=0.1762                                      \n",
            "[2025-11-04 19:41:05] Epoch 13/100: train_loss=0.1762                                      \n",
            "                                                                                    [2025-11-04 19:41:13] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:41:13] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:41:15] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:41:15] Epoch 013/100 | train_loss=0.1762 | val_loss=0.7228 | acc=0.3348 | CER=0.2291 | WER=0.6469 | acc_beam=0.3523 | CER_beam=0.2087 | WER_beam=0.6097 | lr=1.00e-03\n",
            "[2025-11-04 19:41:15] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:41:15] Epoch 013/100 | train_loss=0.1762 | val_loss=0.7228 | acc=0.3348 | CER=0.2291 | WER=0.6469 | acc_beam=0.3523 | CER_beam=0.2087 | WER_beam=0.6097 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013/100 | train_loss=0.1762 | val_loss=0.7228 | acc=0.3348 | CER=0.2291 | WER=0.6469 | acc_beam=0.3523 | CER_beam=0.2087 | WER_beam=0.6097 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:45:19] Epoch 14/100: train_loss=0.1591                                      \n",
            "[2025-11-04 19:45:19] Epoch 14/100: train_loss=0.1591                                      \n",
            "                                                                                    [2025-11-04 19:45:27] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:45:27] Визуализация 10 примеров (greedy) в TensorBoard\n",
            "[2025-11-04 19:45:28] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:45:28] Epoch 014/100 | train_loss=0.1591 | val_loss=0.6017 | acc=0.3905 | CER=0.1734 | WER=0.5761 | acc_beam=0.4048 | CER_beam=0.1642 | WER_beam=0.5525 | lr=1.00e-03\n",
            "[2025-11-04 19:45:28] Визуализация 10 примеров (beam) в TensorBoard\n",
            "[2025-11-04 19:45:28] Epoch 014/100 | train_loss=0.1591 | val_loss=0.6017 | acc=0.3905 | CER=0.1734 | WER=0.5761 | acc_beam=0.4048 | CER_beam=0.1642 | WER_beam=0.5525 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014/100 | train_loss=0.1591 | val_loss=0.6017 | acc=0.3905 | CER=0.1734 | WER=0.5761 | acc_beam=0.4048 | CER_beam=0.1642 | WER_beam=0.5525 | lr=1.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025-11-04 19:45:32] New best val_loss: 0.6017 (epoch 14)\n",
            "[2025-11-04 19:45:34] New best acc: 0.3905 (epoch 14)\n",
            "Train 15/100:   0%|          | 0/1130 [00:00<?, ?it/s][2025-11-04 19:45:34] New best acc: 0.3905 (epoch 14)\n",
            "Train 15/100:  22%|██▏       | 254/1130 [00:55<03:04,  4.75it/s, loss=0.1147, lr=1.00e-03]"
          ]
        }
      ],
      "source": [
        "from manuscript.recognizers import TRBA\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_summary = TRBA.train(\n",
        "        train_csvs= [\n",
        "            r\"C:\\shared\\orig_cyrillic\\train.tsv\",\n",
        "        ],\n",
        "        train_roots= [\n",
        "            r\"C:\\shared\\orig_cyrillic\\train\",\n",
        "        ],\n",
        "        val_csvs= [\n",
        "            r\"C:\\shared\\orig_cyrillic\\test.tsv\",\n",
        "        ],\n",
        "        val_roots= [\n",
        "            r\"C:\\shared\\orig_cyrillic\\test\",\n",
        "        ],\n",
        "        exp_dir=\"experiments/trba_exp4\",\n",
        "        max_len=30,\n",
        "        img_h=32,\n",
        "        img_w=128,\n",
        "        hidden_size=256,\n",
        "        num_encoder_layers=1,\n",
        "        encoder_type=\"GRU\",\n",
        "        decoder_type=\"LSTM\",\n",
        "        use_unet=True,\n",
        "        batch_size=64,\n",
        "        epochs=100,\n",
        "        lr=1e-3,\n",
        "        device=\"cuda\",\n",
        "        dual_validate=True,\n",
        "        pretrain_weights=\"default\",\n",
        "        save_every=1,\n",
        "    )\n",
        "\n",
        "    print(train_summary)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08536258283e4d0686a28b65599b21b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d156619f05d44eda68a2591cc48fc1a",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12479d4b931c40bca2dfd9b2033073a4",
            "value": 383
          }
        },
        "0c01b57d0b4b45f482c4b2af338b3f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12479d4b931c40bca2dfd9b2033073a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d156619f05d44eda68a2591cc48fc1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2181b058d54c44dc92db55d34893b248": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57a8e5f2b99c425db6151351bd1573e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc36ca76a96d427aa457a7c3aeff3c0e",
            "placeholder": "​",
            "style": "IPY_MODEL_e041a221954541bbb65b99109810e1f5",
            "value": " 383/383 [03:44&lt;00:00,  3.15it/s]"
          }
        },
        "ca5f831c6cdd4831a9cf7f8bb90b4083": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db796066b2dc47fe8ebaf0a6d9c85e6e",
            "placeholder": "​",
            "style": "IPY_MODEL_2181b058d54c44dc92db55d34893b248",
            "value": "Train 1: 100%"
          }
        },
        "db796066b2dc47fe8ebaf0a6d9c85e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e041a221954541bbb65b99109810e1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e16b54ce0ba740d28d2a5b3528e26f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca5f831c6cdd4831a9cf7f8bb90b4083",
              "IPY_MODEL_08536258283e4d0686a28b65599b21b0",
              "IPY_MODEL_57a8e5f2b99c425db6151351bd1573e2"
            ],
            "layout": "IPY_MODEL_0c01b57d0b4b45f482c4b2af338b3f0b"
          }
        },
        "fc36ca76a96d427aa457a7c3aeff3c0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
