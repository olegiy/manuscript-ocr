"""
–¢–µ—Å—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ num_encoder_layers –≤ TRBA –º–æ–¥–µ–ª–∏.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
1. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º encoder layers
2. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
3. –ü–∞—Ä–∞–º–µ—Ç—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è/–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
"""

import torch
from manuscript.recognizers._trba.model.model import TRBAModel
from manuscript.recognizers._trba.data.transforms import load_charset
import os

# –ó–∞–≥—Ä—É–∑–∫–∞ charset
current_dir = os.path.dirname(os.path.abspath(__file__))
charset_path = os.path.join(
    current_dir,
    "src",
    "manuscript",
    "recognizers",
    "_trba",
    "configs",
    "charset.txt"
)

itos, stoi = load_charset(charset_path)
num_classes = len(itos)

print("=" * 60)
print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ num_encoder_layers –≤ TRBAModel")
print("=" * 60)

# –¢–µ—Å—Ç 1: –ú–æ–¥–µ–ª—å —Å 1 encoder layer
print("\n1Ô∏è‚É£  –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å num_encoder_layers=1")
model_1layer = TRBAModel(
    num_classes=num_classes,
    hidden_size=256,
    num_encoder_layers=1,
    sos_id=stoi["<SOS>"],
    eos_id=stoi["<EOS>"],
    pad_id=stoi["<PAD>"],
)
print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —Å {model_1layer.num_encoder_layers} encoder layer(s)")
print(f"   Encoder: {len(model_1layer.enc_rnn)} —Å–ª–æ—ë–≤")

# –¢–µ—Å—Ç 2: –ú–æ–¥–µ–ª—å —Å 2 encoder layers (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
print("\n2Ô∏è‚É£  –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å num_encoder_layers=2 (default)")
model_2layers = TRBAModel(
    num_classes=num_classes,
    hidden_size=256,
    num_encoder_layers=2,
    sos_id=stoi["<SOS>"],
    eos_id=stoi["<EOS>"],
    pad_id=stoi["<PAD>"],
)
print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —Å {model_2layers.num_encoder_layers} encoder layer(s)")
print(f"   Encoder: {len(model_2layers.enc_rnn)} —Å–ª–æ—ë–≤")

# –¢–µ—Å—Ç 3: –ú–æ–¥–µ–ª—å —Å 4 encoder layers
print("\n3Ô∏è‚É£  –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å num_encoder_layers=4")
model_4layers = TRBAModel(
    num_classes=num_classes,
    hidden_size=256,
    num_encoder_layers=4,
    sos_id=stoi["<SOS>"],
    eos_id=stoi["<EOS>"],
    pad_id=stoi["<PAD>"],
)
print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —Å {model_4layers.num_encoder_layers} encoder layer(s)")
print(f"   Encoder: {len(model_4layers.enc_rnn)} —Å–ª–æ—ë–≤")

# –¢–µ—Å—Ç 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
print("\n4Ô∏è‚É£  –¢–µ—Å—Ç –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
batch_size = 2
dummy_input = torch.randn(batch_size, 3, 64, 256)

for name, model in [
    ("1 layer", model_1layer),
    ("2 layers", model_2layers),
    ("4 layers", model_4layers)
]:
    model.eval()
    with torch.no_grad():
        probs, preds = model(
            dummy_input,
            is_train=False,
            mode="greedy",
            batch_max_length=25
        )
    print(f"   {name:10s}: Output shape = {probs.shape}, Preds shape = {preds.shape}")

print("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")

# –¢–µ—Å—Ç 5: –ü–æ–¥—Å—á—ë—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
print("\n5Ô∏è‚É£  –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
for name, model in [
    ("1 encoder layer", model_1layer),
    ("2 encoder layers", model_2layers),
    ("4 encoder layers", model_4layers)
]:
    total_params = sum(p.numel() for p in model.parameters())
    encoder_params = sum(p.numel() for p in model.enc_rnn.parameters())
    print(f"   {name:17s}: Total = {total_params:,} params, Encoder = {encoder_params:,} params")

print("\n" + "=" * 60)
print("üéâ –ü–∞—Ä–∞–º–µ—Ç—Ä num_encoder_layers —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
print("=" * 60)
